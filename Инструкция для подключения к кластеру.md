# Кластер

### Внимательно ознакомьтесь с данными инструкциями!!

https://t1-cloud.ru/docs/article/portal-t1-oblako/iam-i-upravlenie/servisnie-akkaunti

https://t1-cloud.ru/docs/article/obektnie-khranilishcha-s3/obektnie-khranilishcha/baketi/nastroika-pravil-dostupa-k-baketu

https://t1-cloud.ru/docs/article/cloud-engine-openstack/cloud-compute/podklyuchenie-k-serveru

---

Кластер состоит из:

- edge node 2/8
- 4 worker nodes 8/32 + 100GB
- S3 bucket

Что вы получите:

- IP вашей edge node
- логин и закрытый ключ для вашей edge node
- access+secret keys для доступа к S3 bucket
- небольшой скрипт для копирования исходных данных с общего бакета в ваш
- референсный скрипт для обработки данных
- скрипт для проверки результата

Зайти на edge node вы можете по ssh:

    ssh -i /path/to/alpha alpha@edge_ip

На кластере установлен Apache Spark. Чтобы включить его, выполните команду

    SPARK_SSH_OPTS='-i /home/alpha/alpha' /opt/spark/sbin/start-all.sh
    
Для остановки, соответственно

    SPARK_SSH_OPTS='-i /home/alpha/alpha' /opt/spark/sbin/stop-all.sh
    
Запуск скрипта тоже прост:

    /opt/spark/bin/spark-submit --jars 

Вы можете что угодно делать со спарком, а также установить другой движок.

# Исходные данные

На бакете s3a://source-data лежат следующие наборы данных:

- init2 и incr2 - маленький набор данных (10млн-1млн), на котором удобно проверять корректность вашего кода
- init3 и incr3 - средний набор данных (100млн-10млн), которым мы будем сравнивать ваши решения по скорости для выбора финалистов
- init4 и incr4 - большой набор данных (1млрд-100млн), на котором мы обязательно проверим финалистов

Таблицы incr копировать не нужно, а вот таблицу init вы должны будете скопировать на свой бакет.
